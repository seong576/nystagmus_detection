{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/seong576/nystagmus_detection/blob/main/Retinal_Project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3mXEYvkyc801"
      },
      "source": [
        "#Retina Detection in Image "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7xtdAqDARkRr"
      },
      "source": [
        "## Image To Numpy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 534
        },
        "id": "XI2gtgd9U19G",
        "outputId": "3047b571-0463-48ca-83cb-d120f84a9f8f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "0\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-4391302a4900>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0max\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplots\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m \u001b[0max\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m12\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcmap\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'gray'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m12\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcmap\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'gray'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: index 12 is out of bounds for axis 0 with size 0"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from skimage.io import imread\n",
        "from skimage.transform import pyramid_reduce, resize\n",
        "import os, glob\n",
        "\n",
        "\n",
        "path = \"/content/drive/MyDrive/train/\"\n",
        "\n",
        "img_list = sorted(glob.glob(path+'data/*/*/*.jpg'))\n",
        "mask_list = sorted(glob.glob(path+'mask/*/*/*.png'))\n",
        "row_size =320\n",
        "col_size = 320\n",
        "\n",
        "x_data, y_data = np.empty((2, len(img_list), row_size, col_size , 1), dtype=np.float32)\n",
        "\n",
        "print(len(mask_list))\n",
        "print(len(img_list))\n",
        "for i, img_path in enumerate(img_list):\n",
        "    img = imread(img_path)\n",
        "    img = resize(img, output_shape=(row_size, col_size , 1), preserve_range=True)\n",
        "    x_data[i] = img\n",
        "      \n",
        "for i, img_path in enumerate(mask_list):\n",
        "    img = imread(img_path)\n",
        "    img = resize(img, output_shape=(row_size, col_size , 1), preserve_range=True)\n",
        "    y_data[i] = img\n",
        "    \n",
        "y_data /= 255.\n",
        "\n",
        "fig, ax = plt.subplots(1, 2)\n",
        "ax[0].imshow(x_data[12].squeeze(), cmap='gray')\n",
        "ax[1].imshow(y_data[12].squeeze(), cmap='gray')\n",
        "\n",
        "\n",
        "x_train, x_val, y_train, y_val = train_test_split(x_data, y_data, test_size=0.1,shuffle=True)\n",
        "\n",
        "np.save(path+'x_train.npy', x_train)\n",
        "np.save(path+'y_train.npy', y_train)\n",
        "np.save(path+'x_val.npy', x_val)\n",
        "np.save(path+'y_val.npy', y_val)\n",
        "\n",
        "print(x_train.shape, y_train.shape)\n",
        "print(x_val.shape, y_val.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OP6NWW8DRwCr"
      },
      "source": [
        "##U-net Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vyVGNRA6BWmC"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from __future__ import print_function\n",
        "import cv2\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from keras.models import Model\n",
        "from keras.layers import Input, concatenate, Dropout, Conv2D, Conv3D\n",
        "from keras.layers import MaxPooling2D, MaxPooling3D, Conv2DTranspose, UpSampling2D\n",
        "from keras.layers import BatchNormalization, Activation\n",
        "from keras.layers import Reshape, Dense, multiply, Add, Concatenate\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from keras.callbacks import ModelCheckpoint, LearningRateScheduler\n",
        "import keras.utils\n",
        "from keras import backend as K\n",
        "from keras import models\n",
        "from keras import callbacks\n",
        "from keras.layers import Input, Activation, Conv2D, Flatten, Dense, MaxPooling2D, Dropout, Add, LeakyReLU, UpSampling2D\n",
        "from keras.models import Model, load_model\n",
        "from keras.callbacks import ReduceLROnPlateau\n",
        "\n",
        "path = \"/content/drive/MyDrive/train/\"\n",
        "\n",
        "x_train = np.load(path+'x_train.npy')\n",
        "y_train = np.load(path+'y_train.npy')\n",
        "x_val = np.load(path+'x_val.npy')\n",
        "y_val = np.load(path+'y_val.npy')\n",
        "smooth = 1.\n",
        "\n",
        "def dice_coef(y_true, y_pred):\n",
        "    y_true_f = K.flatten(y_true)\n",
        "    y_pred_f = K.flatten(y_pred)\n",
        "    intersection = K.sum(y_true_f * y_pred_f)\n",
        "    return (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n",
        "\n",
        "\n",
        "def dice_coef_loss(y_true, y_pred):\n",
        "    return -dice_coef(y_true, y_pred)\n",
        "\n",
        "\n",
        "inputs = Input(shape=(320, 320,1 ))\n",
        "\n",
        "conv1 = Conv2D(32, (3, 3), activation='relu', padding='same')(inputs)\n",
        "batch1 = BatchNormalization()(conv1) \n",
        "conv1 = Conv2D(32, (3, 3), activation='relu', padding='same')(batch1)\n",
        "drop1 = tf.keras.layers.Dropout(0.1)(conv1)\n",
        "pool1 = MaxPooling2D(pool_size=(2, 2))(drop1)\n",
        "\n",
        "\n",
        "conv2 = Conv2D(64, (3, 3), activation='relu', padding='same')(pool1)\n",
        "batch2 = BatchNormalization()(conv2) \n",
        "conv2 = Conv2D(64, (3, 3), activation='relu', padding='same')(batch2)\n",
        "drop2 = tf.keras.layers.Dropout(0.1)(conv2)\n",
        "pool2 = MaxPooling2D(pool_size=(2, 2))(drop2)\n",
        "\n",
        "\n",
        "conv3 = Conv2D(128, (3, 3), activation='relu', padding='same')(pool2)\n",
        "batch3 = BatchNormalization()(conv3) \n",
        "conv3 = Conv2D(128, (3, 3), activation='relu', padding='same')(batch3)\n",
        "drop3 = tf.keras.layers.Dropout(0.1)(conv3)\n",
        "pool3 = MaxPooling2D(pool_size=(2, 2))(drop3)\n",
        "\n",
        "conv4 = Conv2D(256, (3, 3), activation='relu', padding='same')(pool3)\n",
        "batch4 = BatchNormalization()(conv4) \n",
        "conv4 = Conv2D(256, (3, 3), activation='relu', padding='same')(batch4)\n",
        "drop4 = tf.keras.layers.Dropout(0.1)(conv4)\n",
        "pool4 = MaxPooling2D(pool_size=(2, 2))(drop4)\n",
        "\n",
        "conv5 = Conv2D(512, (3, 3), activation='relu', padding='same')(pool4)\n",
        "batch5 = BatchNormalization()(conv5) \n",
        "conv5 = Conv2D(512, (3, 3), activation='relu', padding='same')(batch5)\n",
        "drop5 = tf.keras.layers.Dropout(0.1)(conv5)\n",
        "\n",
        "up6 = concatenate([Conv2DTranspose(256, (2, 2), strides=(2, 2),padding='same')(conv5), conv4], axis=3)\n",
        "conv6 = Conv2D(256, (3, 3), activation='relu', padding='same')(up6)\n",
        "batch6 = BatchNormalization()(conv6) \n",
        "conv6 = Conv2D(256, (3, 3), activation='relu', padding='same')(batch6)\n",
        "\n",
        "up7 = concatenate([Conv2DTranspose(128, (2, 2), strides=(2, 2),\n",
        "                                       padding='same')(conv6), conv3], axis=3)\n",
        "conv7 = Conv2D(128, (3, 3), activation='relu', padding='same')(up7)\n",
        "batch7 = BatchNormalization()(conv7) \n",
        "conv7 = Conv2D(128, (3, 3), activation='relu', padding='same')(batch7)\n",
        "\n",
        "up8 = concatenate([Conv2DTranspose(64, (2, 2), strides=(2, 2),\n",
        "                                       padding='same')(conv7), conv2], axis=3)\n",
        "conv8 = Conv2D(64, (3, 3), activation='relu', padding='same')(up8)\n",
        "batch8 = BatchNormalization()(conv8) \n",
        "conv8 = Conv2D(64, (3, 3), activation='relu', padding='same')(batch8)\n",
        "\n",
        "up9 = concatenate([Conv2DTranspose(32, (2, 2), strides=(2, 2),\n",
        "                                       padding='same')(conv8), conv1], axis=3)\n",
        "conv9 = Conv2D(32, (3, 3), activation='relu', padding='same')(up9)\n",
        "batch9 = BatchNormalization()(conv9) \n",
        "conv9 = Conv2D(32, (3, 3), activation='relu', padding='same')(batch9)\n",
        "\n",
        "conv10 = Conv2D(1, (1, 1), activation='sigmoid')(conv9)\n",
        "model = Model(inputs=[inputs], outputs=[conv10])\n",
        "model.compile(optimizer=Adam(learning_rate=1e-4), loss=dice_coef_loss, metrics=[dice_coef])\n",
        "\n",
        "model_checkpoint = ModelCheckpoint('unet.hdf5', monitor='loss', save_best_only=True)\n",
        "\n",
        "history = model.fit(x_train, y_train, batch_size=16, epochs=20,\n",
        "                        verbose=1, shuffle=True,\n",
        "                        validation_data=(x_val, y_val),callbacks=[model_checkpoint])\n",
        "\n",
        "model.summary()\n",
        "model.save(path+\"Unet\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EPEdvjUbR4OM"
      },
      "source": [
        "##Video to Numpy and Prediction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TueISSMuHvO9"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "import sys\n",
        "import glob\n",
        "from google.colab.patches import cv2_imshow\n",
        "import scipy.misc\n",
        "from skimage.io import imread\n",
        "from skimage.transform import pyramid_reduce, resize\n",
        "model_path = \"/content/drive/MyDrive/train/\"\n",
        "model = keras.models.load_model(model_path+\"Unet\", compile =False)\n",
        "\n",
        "path = \"/content/drive/MyDrive/nystagmus/Rt_Lat_canal/34/\"\n",
        "def video_to_tensor():\n",
        "  cap = cv2.VideoCapture(path+\"bl.avi\")\n",
        "  tensor = []\n",
        "  while cap.isOpened():\n",
        "      ret, image = cap.read()\n",
        "\n",
        "      if not ret:\n",
        "          break\n",
        "      image = resize(image,output_shape= (320, 320,1),preserve_range=True)\n",
        "      gray_img = cv2.cvtColor(image,cv2.COLOR_BGR2GRAY)\n",
        "      tensor.append(np.asarray(gray_img))\n",
        "      cv2.waitKey(0)\n",
        "\n",
        "  tensor = np.array(tensor)\n",
        "  cv2.destroyAllWindows()\n",
        "  cap.release()\n",
        "  return tensor\n",
        "\n",
        "# img_list = sorted(glob.glob(path+'8_hrl,180/*.jpg'))\n",
        "# row_size =320\n",
        "# col_size = 320\n",
        "# x_data = np.empty((len(img_list), row_size, col_size , 1), dtype=np.float32)\n",
        "\n",
        "# print(len(x_data))\n",
        "# for i, img_path in enumerate(img_list):\n",
        "#     img = imread(img_path)\n",
        "#     img = resize(img, output_shape=(row_size, col_size , 1), preserve_range=True)\n",
        "#     x_data[i] = img\n",
        "\n",
        "#x_test = np.asarray(np.load(path+\"x_train.npy\"),dtype=\"uint8\")\n",
        "#preds = np.asarray(np.load(path+\"y_train.npy\"),dtype=\"uint8\")\n",
        "x_test = np.asarray(video_to_tensor())\n",
        "preds = np.asarray(model.predict(x_test))\n",
        "\n",
        "img_rows =320\n",
        "img_cols =320\n",
        "def set_view():\n",
        "    total=x_test.shape[0]\n",
        "    img = np.ndarray((total, img_rows, img_cols), dtype=np.uint8)\n",
        "    mask = np.ndarray((total, img_rows, img_cols), dtype=np.uint8)\n",
        "    kernel = np.ones((5, 5), np.uint8)\n",
        "    dst = np.full((total,img_rows, img_cols),255,dtype=np.uint8)\n",
        "    img = x_test\n",
        "    mask = preds\n",
        "    print(\"total time : {0:0.2f}\".format(total/30))\n",
        "    for m in range(total):\n",
        "        msk = cv2.dilate(mask[m], kernel, iterations=1)\n",
        "        msk = cv2.GaussianBlur(msk, (0,0), 7)\n",
        "        cv2.copyTo(img[m],msk,dst[m])\n",
        "    return dst\n",
        "\n",
        "view_imgs = np.ndarray((x_test.shape[0],img_rows, img_cols), dtype=np.uint8)\n",
        "view_imgs = set_view()\n",
        "for i in range(20):\n",
        "    cv2_imshow(x_test[i,:,:])\n",
        "    cv2_imshow(view_imgs[i,:,:])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OMSrTRAIzz5B"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "path = \"/content/drive/MyDrive/retinal/\"\n",
        "model = keras.models.load_model(path+\"Unet\", compile =False)\n",
        "\n",
        "msk = np.asarray(cv2.imread(path+\"Train_Mask/1.png\",cv2.IMREAD_GRAYSCALE),dtype=\"uint8\")\n",
        "img = cv2.imread(path+\"Train_img/1.jpg\",cv2.IMREAD_GRAYSCALE)\n",
        "x = np.ones((120,320),dtype=\"uint8\")*255\n",
        "cv2_imshow(img)\n",
        "\n",
        "cv2.copyTo(img,msk,x)\n",
        "cv2_imshow(x)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W3KNpDn5cqrH"
      },
      "source": [
        "#Nystagmus Detection "
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Setting"
      ],
      "metadata": {
        "id": "Ti4ZFuMNDgrB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import cv2\n",
        "from sklearn.model_selection import train_test_split\n",
        "from skimage.io import imread\n",
        "import os, glob\n",
        "import keras\n",
        "from keras import optimizers\n",
        "from keras.models import Model\n",
        "from keras.layers import *\n",
        "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "from skimage.transform import resize\n",
        "import shutil\n",
        "\n",
        "path = \"/content/drive/MyDrive/bppv/\"\n",
        "bppv_path = \"/content/drive/MyDrive/nystagmus/\"\n",
        "model_save_path = \"/content/drive/MyDrive/\"\n",
        "\n",
        "approval_range = 6 # The parameter of How many checks to judge nystagmus \n",
        "segment_range = 5 # Interval to Slicing video \n",
        "img_height,  img_width =120,320\n",
        "suffix = \".avi\"\n",
        "#video_list = sorted(glob.glob(path+'/*/*'+suffix))\n",
        "\n",
        "\n",
        "classes = [os.path.basename(x) for x in glob.glob(path+\"/*\") if x not in glob.glob(path+\"/*.*\")]\n",
        "#behavior_class = list(set([os.path.basename(x) for x in glob.glob(bppv_path+\"*/*/*4.avi\")]))\n",
        "behavior_class = list(set([os.path.basename(x) for x in glob.glob(bppv_path+\"/*/*/*.avi\")]))\n",
        "output_class = [os.path.basename(x) for x in glob.glob(bppv_path+\"/*\") if x not in glob.glob(bppv_path+\"/*.*\")]\n",
        "\n",
        "print(\"nystagmus class is : \",end=\"\")\n",
        "print(classes)\n",
        "\n",
        "print(\"behavior class is : \",end=\"\")\n",
        "print(behavior_class)\n",
        "\n",
        "print(\"output class is : \",end=\"\")\n",
        "print(output_class)\n"
      ],
      "metadata": {
        "id": "2mOgEarBDfqs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "824c3ac8-f773-4a67-b4f2-3ece836b97c5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nystagmus class is : ['left_nystagmus', 'normal', 'right_nystagmus']\n",
            "behavior class is : ['blb-자발안진 Rt beating있으나 bowing test할때안진작아지고 leaning tets할때안진커짐).avi', 'blbl.avi', 'ld (2).avi', 'hrr,180.avi', 'ld.avi', 'hrr (2).avi', 'hrl.avi', 'hrl,r.avi', 'hrr,l,r.avi', 'hrl,180 (2).avi', 'hrl 180.avi', 'bl.avi', 'hrr.avi', 'hrl,180.avi']\n",
            "output class is : ['Lt_Lat_canal', 'Rt_Lat_canal']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oepq3ad5cL2_"
      },
      "source": [
        "##Make DataSet To Numpy\n",
        " * processing for Convlstm Input"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "boPY1BqUZzL7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "828cc3b9-ea64-4ef6-9d60-7bae349062dd"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(375, 3)\n"
          ]
        }
      ],
      "source": [
        "[os.remove(f) for f in glob.glob(path+\"/.DS_Store\")]\n",
        "[os.remove(f) for f in glob.glob(path+\"/*/.DS_Store\")]\n",
        "[os.remove(f) for f in glob.glob(path+'x_train.npy')]\n",
        "[os.remove(f) for f in glob.glob(path+'y_train.npy')]\n",
        "[os.remove(f) for f in glob.glob(path+'x_val.npy')]\n",
        "[os.remove(f) for f in glob.glob(path+'y_val.npy')]\n",
        "\n",
        "def frames_extraction_and_create(video_path):\n",
        "    frames_list = []\n",
        "    X = []\n",
        "    Y = np.zeros((len(glob.glob(path+\"*/*/\")),len(classes)),dtype = int)\n",
        "    print(Y.shape)\n",
        "    for c in classes: #nystagmus, runout\n",
        "        files_list = os.listdir(os.path.join(path,c))\n",
        "        for files in files_list: # 45,46,51....\n",
        "          file_img = os.listdir(os.path.join(path,c+\"/\"+files))\n",
        "          for segment in file_img: #334.jpg 335.jpg\n",
        "              if segment.find(\"jpg\") != -1:\n",
        "                  image = cv2.imread(os.path.join(path,c+\"/\"+files+\"/\"+segment))\n",
        "                  image = resize(image, output_shape=(img_height,  img_width))\n",
        "                  frames_list.append(np.uint8(image*255))\n",
        "          X.append(frames_list)\n",
        "          frames_list = []\n",
        "          Y[len(X)-1,classes.index(c)]=1\n",
        "    Y=np.asarray(Y)\n",
        "    X=np.asarray(X)\n",
        "    return X,Y\n",
        "\n",
        "X,Y=frames_extraction_and_create(path)\n",
        "x_train, x_val, y_train, y_val = train_test_split(X, Y, test_size=0.3,shuffle=True)\n",
        "\n",
        "np.save(path+'x_train.npy', x_train)\n",
        "np.save(path+'y_train.npy', y_train)\n",
        "np.save(path+'x_val.npy', x_val)\n",
        "np.save(path+'y_val.npy', y_val)\n",
        "\n",
        "print(x_train.shape, y_train.shape)\n",
        "print(x_val.shape, y_val.shape)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oUyfW6fgLJNF"
      },
      "source": [
        "##Classifier Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "pLyUt4L9BoAL",
        "outputId": "80f3097a-e9ff-4a62-b8b2-8958189b6c00"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 15, 120, 320, 3)  0         \n",
            "                             ]                                   \n",
            "                                                                 \n",
            " conv3d_2 (Conv3D)           (None, 11, 116, 316, 64)  24064     \n",
            "                                                                 \n",
            " max_pooling3d_2 (MaxPooling  (None, 11, 24, 64, 64)   0         \n",
            " 3D)                                                             \n",
            "                                                                 \n",
            " batch_normalization_2 (Batc  (None, 11, 24, 64, 64)   256       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 11, 24, 64, 64)    0         \n",
            "                                                                 \n",
            " conv3d_3 (Conv3D)           (None, 9, 22, 62, 64)     110656    \n",
            "                                                                 \n",
            " max_pooling3d_3 (MaxPooling  (None, 9, 8, 21, 64)     0         \n",
            " 3D)                                                             \n",
            "                                                                 \n",
            " batch_normalization_3 (Batc  (None, 9, 8, 21, 64)     256       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 9, 8, 21, 64)      0         \n",
            "                                                                 \n",
            " conv3d_4 (Conv3D)           (None, 9, 8, 21, 64)      4160      \n",
            "                                                                 \n",
            " max_pooling3d_4 (MaxPooling  (None, 9, 8, 21, 64)     0         \n",
            " 3D)                                                             \n",
            "                                                                 \n",
            " batch_normalization_4 (Batc  (None, 9, 8, 21, 64)     256       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " dropout_4 (Dropout)         (None, 9, 8, 21, 64)      0         \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 96768)             0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 1024)              99091456  \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 256)               262400    \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 3)                 771       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 99,494,275\n",
            "Trainable params: 99,493,891\n",
            "Non-trainable params: 384\n",
            "_________________________________________________________________\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-340cf1687f62>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_Model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m \u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0mearlystop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mEarlyStopping\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpatience\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-5-340cf1687f62>\u001b[0m in \u001b[0;36mload_data\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mload_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m   \u001b[0mx_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'x_train.npy'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mallow_pickle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m   \u001b[0my_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'y_train.npy'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mallow_pickle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m   \u001b[0mx_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'x_val.npy'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mallow_pickle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'y_val.npy'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mallow_pickle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(file, mmap_mode, allow_pickle, fix_imports, encoding)\u001b[0m\n\u001b[1;32m    415\u001b[0m             \u001b[0mown_fid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    416\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 417\u001b[0;31m             \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstack\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menter_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos_fspath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    418\u001b[0m             \u001b[0mown_fid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    419\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/MyDrive/bppv/x_train.npy'"
          ]
        }
      ],
      "source": [
        "def load_data(path):\n",
        "  x_train = np.load(path+'x_train.npy',allow_pickle=True)\n",
        "  y_train = np.load(path+'y_train.npy',allow_pickle=True)\n",
        "  x_test = np.load(path+'x_val.npy',allow_pickle=True)\n",
        "  y_test = np.load(path+'y_val.npy',allow_pickle=True)\n",
        "  print(\"Data load is done...\")\n",
        "  return x_train,x_test,y_train,y_test\n",
        "\n",
        "def get_Model():\n",
        "  inp = keras.layers.Input(shape=(15,120,320,3))\n",
        "\n",
        "  x = keras.layers.Conv3D(filters=64,kernel_size=(9,9,9),activation=\"tanh\")(inp)\n",
        "  x = keras.layers.MaxPooling3D(pool_size = (3,9,9),padding ='same')(x)\n",
        "  x = keras.layers.BatchNormalization()(x)\n",
        "  x = keras.layers.Dropout(0.2)(x)\n",
        "\n",
        "  x = keras.layers.Conv3D(filters=64,kernel_size=(7, 7,7),activation=\"tanh\")(inp)\n",
        "  x = keras.layers.MaxPooling3D(pool_size = (2,7,7),padding ='same')(x)\n",
        "  x = keras.layers.BatchNormalization()(x)\n",
        "  x = keras.layers.Dropout(0.2)(x)\n",
        "\n",
        "  x = keras.layers.Conv3D(filters=64,kernel_size=(5, 5,5),activation=\"tanh\")(inp)\n",
        "  x = keras.layers.MaxPooling3D(pool_size = (1,5,5),padding ='same')(x)\n",
        "  x = keras.layers.BatchNormalization()(x)\n",
        "  x = keras.layers.Dropout(0.2)(x)\n",
        "\n",
        "  x = keras.layers.Conv3D(filters=64,kernel_size=(3, 3,3),activation=\"tanh\")(x)\n",
        "  x = keras.layers.MaxPooling3D(pool_size = (1,3,3),padding ='same')(x)\n",
        "  x = keras.layers.BatchNormalization()(x)\n",
        "  x = keras.layers.Dropout(0.2)(x)\n",
        "\n",
        "  x = keras.layers.Conv3D(filters=64,kernel_size=(1, 1,1),activation=\"tanh\")(x)\n",
        "  x = keras.layers.MaxPooling3D(pool_size = (1,1,1),padding ='same')(x)\n",
        "  x = keras.layers.BatchNormalization()(x)\n",
        "  x = keras.layers.Dropout(0.2)(x)\n",
        "\n",
        "  x = keras.layers.Flatten()(x)\n",
        "  x = keras.layers.Dense(1024,activation = \"relu\")(x)\n",
        "  x = keras.layers.Dense(256,activation = \"relu\")(x)\n",
        "  x = keras.layers.Dense(len(classes),activation = \"softmax\")(x)\n",
        "\n",
        "  model = keras.models.Model(inp, x)\n",
        "  opt = tf.keras.optimizers.Adam(learning_rate=0.0000005)\n",
        "  model.compile(loss=tf.keras.losses.categorical_crossentropy, optimizer=opt, metrics=[\"accuracy\"])\n",
        "  model.summary()\n",
        "  #model.save(model_save_path+\"Classifier\")\n",
        "  #model.save(\"Classifier_model.\bh5\")\n",
        "  return model\n",
        "\n",
        "model = get_Model()\n",
        "x_train, x_test, y_train, y_test = load_data(path)\n",
        "\n",
        "earlystop = EarlyStopping(patience=7)\n",
        "early_stopping = keras.callbacks.EarlyStopping(monitor=\"loss\", patience=10)\n",
        "reduce_lr = keras.callbacks.ReduceLROnPlateau(monitor=\"loss\", patience=5)\n",
        "cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=model_save_path+\"Classifier\",\n",
        "                                                 save_weights_only=True,\n",
        "                                                 verbose=0)\n",
        "# Define modifiable training hyperparameters.\n",
        "epochs = 20\n",
        "batch_size = 6\n",
        "\n",
        "# Fit the model to the training data.\n",
        "history = model.fit(\n",
        "    x_train,\n",
        "    y_train,\n",
        "    batch_size=batch_size,\n",
        "    epochs=epochs,\n",
        "    callbacks=[early_stopping, reduce_lr,cp_callback],\n",
        "    validation_data=(x_test, y_test)\n",
        ")\n",
        "\n",
        "test_loss, test_acc = model.evaluate(x_test,  y_test, verbose=2)\n",
        "print('\\nTest accuracy:', test_acc)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Make Context Vector and Image Restoration\n",
        "\n",
        "*   Image_Slicer \n",
        "*   Image_Restoration\n",
        "*   make_context_vector\n",
        "\n",
        "\n",
        " "
      ],
      "metadata": {
        "id": "NhsE5Fr3tFjo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from numpy.core.numeric import zeros_like\n",
        "[shutil.rmtree(f) for f in glob.glob(bppv_path+'/*/*/pred')]\n",
        "\n",
        "def Img_Slicer(video):\n",
        "  # original video tensor [N,120,320,3]\n",
        "  tensor = [] \n",
        "  cap = cv2.VideoCapture(video)\n",
        "  if cap.isOpened():\n",
        "    while True:\n",
        "      ret, img_color = cap.read()\n",
        "      if ret:\n",
        "          img = resize(img_color, output_shape=(img_height,  img_width))\n",
        "          tensor.append(np.uint8(img*255))\n",
        "      else:\n",
        "          break\n",
        "  else:\n",
        "      print(\"파일읽기 불가능\")\n",
        "  tensor = np.array(tensor)\n",
        "  sliced_img =[]\n",
        "  index = 0\n",
        "\n",
        "  # ex) (1000,120,320,3) => 1000/5(segment_range)=> 200-(15/5)-1 = 198 => (198,15,120,320,3)\n",
        "  loop = (len(tensor)/segment_range)-int(15/segment_range)-1\n",
        "  for i in range(int(loop)):\n",
        "  # segment_range = 5 => [[0~15],[5,20],[10,25]...]\n",
        "      sliced_img.append(tensor[(index*segment_range):(index*segment_range)+15]) \n",
        "      index=index+1\n",
        "\n",
        "  sliced_img = np.array(sliced_img)\n",
        "  return sliced_img # output => (N,15,120,320,3)\n",
        "\n",
        "def Image_Restoration(video_path,data_tensor,pred):\n",
        "  print(\"Make Video....\")\n",
        "  idx = 0\n",
        "  if os.path.isdir(os.path.dirname(video_path)+\"/pred\")==False:\n",
        "    os.mkdir(os.path.dirname(video_path)+\"/pred\")\n",
        "  pred = np.asarray(model.predict(data_tensor),dtype=np.float32)\n",
        "  fourcc = cv2.VideoWriter_fourcc('M','J','P','G')\n",
        "  #ex) nystagmus/Lt.Lat.canal/1/pred/bl_output.avi\n",
        "  out = cv2.VideoWriter(os.path.dirname(video_path)+\"/pred/\"+os.path.basename(video_path).replace(suffix,\"\")+'_output.avi', fourcc, 30.0, (img_width,img_height))\n",
        "  print(\"savename : \"+os.path.basename(video_path).replace(suffix,\"\")+'_output.avi')\n",
        "  print(\"======================================\")\n",
        "  for data in data_tensor:\n",
        "    for i in range(0,segment_range):\n",
        "  #(N,15,120,320,3) => [0,5][6,10][11,15]... => restoration(N,120,320,3)\n",
        "        cv2.putText(data[i],classes[pred[idx].argmax()],(10,20),cv2.FONT_HERSHEY_SIMPLEX,0.4,(255,255,255),1)\n",
        "        out.write(data[i])\n",
        "    idx=idx+1\n",
        "\n",
        "  out.release()\n",
        "  cv2.destroyAllWindows()\n",
        "\n",
        "def make_context_vector(model,video_list,approval_range):\n",
        "  # initialize\n",
        "  behavior_dict={}\n",
        "  for c in behavior_class:\n",
        "    behavior_dict[c] = -1\n",
        "  patient_behavior_dict={}\n",
        "\n",
        "  # make Sliced Video (N,15,320,120,3)\n",
        "  for video in video_list:\n",
        "    print(\"video name : \"+os.path.basename(video))\n",
        "    preds = np.asarray(model.predict(Img_Slicer(video)),dtype=np.float32)\n",
        "    #Image_Restoration(video,Img_Slicer(video),preds)\n",
        "    patient_behavior_dict[os.path.basename(video)]=preds\n",
        "  #{bl.avi:[[0.5,0,5],[0.7,0.3]....](Prediction in 15segment)}\n",
        "\n",
        "  lst = [0 for x in range(len(classes))] #[0,0,0]\n",
        "  for key in patient_behavior_dict.keys(): #[rt_nystagmus, normal, lt_nystagmus]\n",
        "    for i in range(len(patient_behavior_dict[key])-approval_range):\n",
        "      store=[patient_behavior_dict[key][x].argmax() for x in range(i,i+approval_range-1)]\n",
        "      if store.count(patient_behavior_dict[key][i].argmax()) == approval_range-1 and patient_behavior_dict[key][i].argmax() != classes.index(\"normal\"):\n",
        "          lst[patient_behavior_dict[key][i].argmax()] = 1\n",
        "          behavior_dict[key.replace(path,\"\")] = lst\n",
        "    lst = [0 for x in range(len(classes))]\n",
        "  \n",
        "  print(behavior_dict)\n",
        "  context_vector = list(behavior_dict.values())\n",
        "  return context_vector # ex) [[0,1,1,0],[0,0,1,0].[1,0,0,0],[-1,-1,-1,-1]]\n",
        "\n",
        "print(classes)\n",
        "ctv = make_context_vector(model,glob.glob(bppv_path+\"*/*/bl.avi\"),4)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 890
        },
        "id": "EKSfExClt1LS",
        "outputId": "af49f5eb-0c53-476c-f132-0f154b2ee5d5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['left_nystagmus', 'normal', 'right_nystagmus']\n",
            "video name : hrl 180.avi\n",
            "video name : ld.avi\n",
            "video name : hrl,180 (2).avi\n",
            "video name : bl.avi\n",
            "video name : hrr.avi\n",
            "video name : ld.avi\n",
            "video name : bl.avi\n",
            "video name : hrl.avi\n",
            "video name : hrl,180.avi\n",
            "video name : hrr.avi\n",
            "video name : hrr (2).avi\n",
            "video name : hrl,180.avi\n",
            "video name : hrr.avi\n",
            "video name : ld.avi\n",
            "video name : hrl,180.avi\n",
            "video name : hrr.avi\n",
            "video name : ld.avi\n",
            "video name : hrl,180.avi\n",
            "video name : hrr.avi\n",
            "video name : bl.avi\n",
            "video name : hrl 180.avi\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ResourceExhaustedError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-7bc5da3be49b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclasses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 82\u001b[0;31m \u001b[0mctv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_context_vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mglob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbppv_path\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"*/*/*.avi\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-7-7bc5da3be49b>\u001b[0m in \u001b[0;36mmake_context_vector\u001b[0;34m(model, video_list, approval_range)\u001b[0m\n\u001b[1;32m     61\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mvideo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvideo_list\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"video name : \"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbasename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvideo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m     \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mImg_Slicer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvideo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m     \u001b[0;31m#Image_Restoration(video,Img_Slicer(video),preds)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0mpatient_behavior_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbasename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvideo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 55\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     56\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mResourceExhaustedError\u001b[0m: Graph execution error:\n\nOOM when allocating tensor with shape[32,11,116,316,64] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node model/conv3d_2/BiasAdd-0-0-TransposeNCDHWToNDHWC-LayoutOptimizer}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n [Op:__inference_predict_function_12994]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def context_vector_Labeler(path):\n",
        "    #bppv_class = filter(os.path.isdir,glob.glob(path+\"/*\"))#[\"Left_LC_BPPV\",\"LeftAC_BPPV\",\"LeftPC_BPPV\",\"Right_LC_BPPV\",\"Right_AC_BPPV\",\"Right_PC_BPPV\"]\n",
        "    bppv_class = [os.path.basename(x) for x in glob.glob(bppv_path+\"/*\") if x not in glob.glob(path+\"/*.*\")]\n",
        "    Y = np.zeros((len(glob.glob(path+\"/*/*\")),len(bppv_class)),dtype = int) #(N,6) dim. ex) bppv(path) -> lat_canal_bppv -> 1,2,3 -> video\n",
        "    print(bppv_class)\n",
        "    X = []\n",
        "    class_folder =glob.glob(path+\"/*\") #ex) bppv(path) -> lat_canal_bppv...(class_folder) -> 1,2,3 -> video\n",
        "    for bppv in class_folder:\n",
        "        video_folder = glob.glob(bppv+\"/*\") #ex) bppv(path) -> ../lat_canal_bppv...(class_folder) -> 1,2,3 (video_folder)-> video\n",
        "        class_folder_base = os.path.basename(bppv) # lat_canal_bppv, ... [mov,fix] -> class_folder_base = fix\n",
        "        for video in video_folder: #1,2,3,4,5.... N num of video_folder\n",
        "          X.append(make_context_vector(model,glob.glob(video+\"/*.MOV\"))) #bl.avi, hrr.avi...  => [0,1,1,0] make shape of context vector\n",
        "          Y[len(X)-1,bppv_class.index(class_folder_base)]=1\n",
        "          \n",
        "    X = np.array(X)\n",
        "    Y = np.array(Y)\n",
        "    x_train, x_val, y_train, y_val = train_test_split(X, Y, test_size=0.3,shuffle=True)\n",
        "    np.save(path+'x_train_context.npy', x_train)\n",
        "    np.save(path+'y_train_context.npy', y_train)\n",
        "    np.save(path+'x_val_context.npy', x_val)\n",
        "    np.save(path+'y_val_context.npy', y_val)\n",
        "\n",
        "def load_context_data(path):\n",
        "  x_train = np.load(path+'x_train_context.npy',allow_pickle=True)\n",
        "  y_train = np.load(path+'y_train_context.npy',allow_pickle=True)\n",
        "  x_test = np.load(path+'x_val_context.npy',allow_pickle=True)\n",
        "  y_test = np.load(path+'y_val_context.npy',allow_pickle=True)\n",
        "  print(\"Data load is done...\")\n",
        "  return x_train,x_test,y_train,y_test\n",
        "\n",
        "def Get_BPPV_Classifier_Model(context_vector):\n",
        "    inp = keras.layers.Input(shape=(np.shape(context_vector)))\n",
        "    x = keras.layers.Dense(1024,activation = \"relu\")(inp)\n",
        "    x = keras.layers.BatchNormalization()(x)\n",
        "    x = keras.layers.Dropout(0.2)(x)\n",
        "\n",
        "    x = keras.layers.Dense(256,activation = \"relu\")(x)\n",
        "    x = keras.layers.BatchNormalization()(x)\n",
        "    x = keras.layers.Dropout(0.2)(x)\n",
        "    \n",
        "    x = keras.layers.Dense(len(output_class),activation = \"softmax\")(x)\n",
        "    model = keras.models.Model(inp, x)\n",
        "\n",
        "    opt = tf.keras.optimizers.Adam(learning_rate=0.0000005)\n",
        "    model.compile(loss=tf.keras.losses.categorical_crossentropy, optimizer=opt, metrics=[\"accuracy\"])\n",
        "    model.summary()\n",
        "    #model.save(path+\"BPPV_Classifier\")\n",
        "    return model\n",
        "\n",
        "context_vector_Labeler(bppv_path)\n",
        "x_train, x_test, y_train, y_test = load_context_data(bppv_path) #->지정\n",
        "print(x_train[0].shape)\n",
        "bppv_model = Get_BPPV_Classifier_Model(x_train[0]) \n",
        "\n",
        "earlystop = EarlyStopping(patience=7)\n",
        "callbacks = [earlystop]\n",
        "early_stopping = keras.callbacks.EarlyStopping(monitor=\"loss\", patience=10)\n",
        "reduce_lr = keras.callbacks.ReduceLROnPlateau(monitor=\"loss\", patience=5)\n",
        "\n",
        "# Define modifiable training hyperparameters.\n",
        "epochs = 30\n",
        "batch_size = 8\n",
        "\n",
        "# Fit the model to the training data.\n",
        "history = bppv_model.fit(\n",
        "    x_train,\n",
        "    y_train,\n",
        "    batch_size=batch_size,\n",
        "    epochs=epochs,\n",
        "    callbacks=[early_stopping, reduce_lr],\n",
        "    validation_data=(x_test, y_test)\n",
        ")\n",
        "\n",
        "test_loss, test_acc = bppv_model.evaluate(x_test, y_test, verbose=2)\n",
        "\n",
        "print('\\nTest accuracy:', test_acc)"
      ],
      "metadata": {
        "id": "tkZsfPprDzuT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a = [0 for i in range(4)]\n",
        "a = np.array(a)\n",
        "print(a[0:3].all() == 0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oIuWMiTt50Rd",
        "outputId": "6878195e-1e24-4f4f-acdc-ad6e87ad4637"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "3mXEYvkyc801"
      ],
      "machine_shape": "hm",
      "name": "Retinal_Project.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}